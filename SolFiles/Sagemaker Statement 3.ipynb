{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To deploy the model in sagemaker\n",
    "\n",
    "**Importing Important Libraries**<br>\n",
    "**Steps To Be Followed**\n",
    "\n",
    "    Importing necessary Libraries\n",
    "    Creating S3 bucket\n",
    "    Mapping train And Test Data in S3\n",
    "    Mapping The path of the models in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session\n",
    "import os\n",
    "#! pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize Your Resources**\n",
    "\n",
    "SageMaker need unique training jobs instance to run, and as a user you need to be able to see your job! So here we will provide our name, and use that to track our resources throughout the lab.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "        Here we use our S3 bucket and prefix for training and modelling data. This will be within the same region as the   Notebook Instance, training, and hosting. If we don't give bucket, SageMaker SDK will create a default bucket with pre defined naming convention.\n",
    "    The IAM role ARN will give SageMaker access to data. It can be fetched using the get_execution_role method from sagemaker python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let we give our bucket name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-southeast-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'youtubecommentanalysis' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the bucket with given prefix name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can go to the S3 option in AWS and can see we created the bucket successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://youtubecommentanalysis/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we continue from the Nootebook result of Cleaning Data, using comment_clean_dataset results, let we get the data in form\n",
    "# numerical data, and for sagemaker we should have output column in first and rest features in other columns\n",
    "# This is the requirement for sagemaker model training and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>commentLikesCount</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgxsNXiQRd3_KsLgdPV4AaABAg</td>\n",
       "      <td>BRMS3T11Cdw</td>\n",
       "      <td>0</td>\n",
       "      <td>I  am  agricultural  engineering  in  machine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugxyg6P0ohA7sUMdyTN4AaABAg</td>\n",
       "      <td>BRMS3T11Cdw</td>\n",
       "      <td>1</td>\n",
       "      <td>i  am  from  the  mechanical  engineering  bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgynJARwxVpywHiSMPh4AaABAg</td>\n",
       "      <td>BRMS3T11Cdw</td>\n",
       "      <td>0</td>\n",
       "      <td>What  are  the  prerequisite  for  this  cours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgxurtxhcNEWR_1sAW54AaABAg</td>\n",
       "      <td>BRMS3T11Cdw</td>\n",
       "      <td>1</td>\n",
       "      <td>there  are  many  videos    which  one  to  st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugy9hN39JI5EjSPpx694AaABAg</td>\n",
       "      <td>BRMS3T11Cdw</td>\n",
       "      <td>0</td>\n",
       "      <td>www  mltut  com  For  machine  Learning  blogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    commentId      videoId  commentLikesCount  \\\n",
       "0  UgxsNXiQRd3_KsLgdPV4AaABAg  BRMS3T11Cdw                  0   \n",
       "1  Ugxyg6P0ohA7sUMdyTN4AaABAg  BRMS3T11Cdw                  1   \n",
       "2  UgynJARwxVpywHiSMPh4AaABAg  BRMS3T11Cdw                  0   \n",
       "3  UgxurtxhcNEWR_1sAW54AaABAg  BRMS3T11Cdw                  1   \n",
       "4  Ugy9hN39JI5EjSPpx694AaABAg  BRMS3T11Cdw                  0   \n",
       "\n",
       "                                            comments  \n",
       "0  I  am  agricultural  engineering  in  machine ...  \n",
       "1  i  am  from  the  mechanical  engineering  bac...  \n",
       "2  What  are  the  prerequisite  for  this  cours...  \n",
       "3  there  are  many  videos    which  one  to  st...  \n",
       "4     www  mltut  com  For  machine  Learning  blogs  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_clean = pd.read_csv(\"comment_clean_dataset.csv\")\n",
    "comments_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting sentiment polarity using textBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_clean['comment_polarity'] = comments_clean['comments'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_clean = comments_clean.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting for 0-> Negative sentiments and 1 -> positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "comments_clean['comment_pol_cat']  = 0\n",
    "comments_clean['comment_pol_cat'][comments_clean.comment_polarity > 0] = 1\n",
    "comments_clean['comment_pol_cat'][comments_clean.comment_polarity <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(line):\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will remove all the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_clean['stop_comments'] = comments_clean['comments'].apply(lambda x : remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_comment = comments_clean['stop_comments'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_comment = tokenized_comment.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_comment)):\n",
    "    tokenized_comment[i] = ' '.join(tokenized_comment[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_clean['token_comments'] = tokenized_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "# bag-of-words feature matrix\n",
    "bow_dataset = bow_vectorizer.fit_transform(comments_clean['token_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This steps weill give us vectorised form of data that we can use to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 1019)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dataset.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_label = comments_clean[['comment_pol_cat']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the comment labels and our comment data in vectorised form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset = pd.DataFrame(np.concatenate((comment_label,bow_dataset.toarray()),axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 1020) (55, 1020)\n"
     ]
    }
   ],
   "source": [
    "# Splitting in training and testing set\n",
    "train_data, test_data = np.split(result_dataset.sample(frac=1, random_state=1729), [int(0.8 * len(result_dataset))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1010</th>\n",
       "      <th>1011</th>\n",
       "      <th>1012</th>\n",
       "      <th>1013</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1020 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  1010  \\\n",
       "26      1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "222     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "165     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "32      1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5       1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "     1011  1012  1013  1014  1015  1016  1017  1018  1019  \n",
       "26      0     0     0     0     0     0     0     0     0  \n",
       "222     0     0     0     0     0     0     0     0     0  \n",
       "165     0     0     0     0     0     0     0     0     0  \n",
       "32      0     0     0     0     0     0     0     0     0  \n",
       "5       0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1020 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we got the data we want let we just see first few rows\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1010</th>\n",
       "      <th>1011</th>\n",
       "      <th>1012</th>\n",
       "      <th>1013</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1020 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  1010  \\\n",
       "115     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "260     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "263     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "51      1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "167     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "     1011  1012  1013  1014  1015  1016  1017  1018  1019  \n",
       "115     0     0     0     0     0     0     0     0     0  \n",
       "260     0     0     0     0     0     0     0     0     0  \n",
       "263     0     0     0     0     0     0     0     0     0  \n",
       "51      0     0     0     0     1     0     0     0     1  \n",
       "167     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1020 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data train and test in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Now let we save the data in local and then Train data into bucket\n",
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Test Data Into Buckets\n",
    "test_data.to_csv('test.csv',index = False,header = False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the predefined inbuild xgboost model to train in container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = get_image_uri(boto3.Session().region_name,\n",
    "                          'xgboost', \n",
    "                          repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now once this step is done, we are ready to train with our estimator and input and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-24 14:10:55 Starting - Starting the training job...\n",
      "2020-10-24 14:10:58 Starting - Launching requested ML instances......\n",
      "2020-10-24 14:12:26 Starting - Preparing the instances for training...\n",
      "2020-10-24 14:12:54 Downloading - Downloading input data...\n",
      "2020-10-24 14:13:00 Training - Downloading the training image.\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:13:29] 219x1019 matrix with 223161 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:13:29] 55x1019 matrix with 56045 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 219 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 55 rows\u001b[0m\n",
      "\u001b[34m[14:13:29] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.42009#011validation-error:0.45454\u001b[0m\n",
      "\n",
      "2020-10-24 14:13:41 Uploading - Uploading generated training model\n",
      "2020-10-24 14:13:41 Completed - Training job completed\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now depending upon the estimators hyperparameters, we can tune it and observe the validation error.\n",
    "# Now once it is done, we can deploy it in sagemaker using this command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now our Model have been deployed in sagemaker successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
